{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1876d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#import tensorflow_decision_forests as tfdf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe431e",
   "metadata": {},
   "source": [
    "### Club all the traces together into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4adecc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './traces/'# use your path\n",
    "#all_files = glob.glob(path + \"/*.h5\")\n",
    "all_files = glob.glob(path + \"/dpotrf_T_*_N_20k-*.prof.h5\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    trace =  pd.HDFStore(filename)\n",
    "    data = trace.get('/events')\n",
    "    trace.close()\n",
    "    \n",
    "    li.append(data)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f6924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(li))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0d6ba",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702d9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(li)):\n",
    "    li[i] = li[i][['begin', 'end', 'taskpool_id', 'task_class_id','chore_id', 'nb_data_items', 'total_data_size', 'priority']].copy()\n",
    "    li[i]['exec_time'] = (li[i]['end'] - li[i]['begin']) * .001 #0.001 nano seconds to micro seconds\n",
    "    li[i] = li[i].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd301c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_name = {0: 'dpotrf', 1: 'dtrsm', 2: 'dsyrk', 3: 'dgemm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b83021",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(li)):\n",
    "    filter = ( (li[i]['task_class_id'] >= 0 ) & ( li[i]['task_class_id'] <= 3 ) & ( li[i]['priority'] >= 0 ) )\n",
    "    #remove all other classes other than dpotrf, dgemm, trsm and syrk\n",
    "    li[i] = li[i][filter]\n",
    "    li[i].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c327c",
   "metadata": {},
   "source": [
    "## integrate likelihood of the data being in cash.\n",
    "we assume that all the task whose execution time is in the first quartile could have had all its data in the cache. While, the rest of the tasks would have resulted in a cache flush. While predicting we assume that the that the data of the task is not in the cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4aea73e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>taskpool_id</th>\n",
       "      <th>task_class_id</th>\n",
       "      <th>chore_id</th>\n",
       "      <th>nb_data_items</th>\n",
       "      <th>total_data_size</th>\n",
       "      <th>priority</th>\n",
       "      <th>exec_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>983020197.0</td>\n",
       "      <td>985542618.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>732924.0</td>\n",
       "      <td>2522.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>985588651.0</td>\n",
       "      <td>986180220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>805509.0</td>\n",
       "      <td>591.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>986207271.0</td>\n",
       "      <td>986783456.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>707183.0</td>\n",
       "      <td>576.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>986806269.0</td>\n",
       "      <td>987403878.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>665169.0</td>\n",
       "      <td>597.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>987428517.0</td>\n",
       "      <td>988010563.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>729588.0</td>\n",
       "      <td>582.046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           begin          end  taskpool_id  task_class_id  chore_id  \\\n",
       "127  983020197.0  985542618.0          4.0            3.0       0.0   \n",
       "128  985588651.0  986180220.0          4.0            3.0       0.0   \n",
       "129  986207271.0  986783456.0          4.0            3.0       0.0   \n",
       "130  986806269.0  987403878.0          4.0            3.0       0.0   \n",
       "131  987428517.0  988010563.0          4.0            3.0       0.0   \n",
       "\n",
       "     nb_data_items  total_data_size  priority  exec_time  \n",
       "127            3.0         960000.0  732924.0   2522.421  \n",
       "128            3.0         960000.0  805509.0    591.569  \n",
       "129            3.0         960000.0  707183.0    576.185  \n",
       "130            3.0         960000.0  665169.0    597.609  \n",
       "131            3.0         960000.0  729588.0    582.046  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li[2][li[2]['task_class_id'] == 3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf57685",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c8c0f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 07:53:31.738348: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "new_LR_model = tf.keras.models.load_model('./LR_model_all_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c7e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_DNN_model = tf.keras.models.load_model('./DNN_all_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f224f048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual = 348.527 LR_predicted [[239.487]] DNN_predicted [[287.472]]\n",
      "----------------- Class 2 -------------------------- \n",
      "Min = 292.163\n",
      "Max = 36786.868\n",
      "Avg = 1974.9610200000004\n",
      "Std = 6806.272262886053\n"
     ]
    }
   ],
   "source": [
    "# nb_data_items total_data_size priority cache_likelihood task_class_0.0 task_class_1.0 task_class_2.0 task_class_3.0\n",
    "\n",
    "LR_predicted = new_LR_model.predict([1.0, 320000.0, 804357.0, 0, 1, 0, 0, 0])\n",
    "DNN_predicted = new_DNN_model.predict([1.0, 320000.0, 1804357.0, 0, 1, 0, 0, 0])\n",
    "Actual = '348.527'\n",
    "print('Actual = ' + str(Actual) + ' LR_predicted ' + str(LR_predicted) + ' DNN_predicted ' + str(DNN_predicted))\n",
    "\n",
    "filter = (li[2]['task_class_id'] == 0 )\n",
    "df_2 = li[2][filter]\n",
    "print('----------------- Class 2 -------------------------- ')\n",
    "print('Min = ' + str(df_2['exec_time'].min()))\n",
    "print('Max = ' + str(df_2['exec_time'].max()))\n",
    "print('Avg = ' + str(sum(df_2['exec_time']) / len(df_2['exec_time'])))\n",
    "print('Std = ' + str(df_2['exec_time'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa9a5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual = 566.124 LR_predicted [[521.365]] DNN_predicted [[559.016]]\n",
      "----------------- Class 2 -------------------------- \n",
      "Min = 242.71200000000002\n",
      "Max = 46661.549\n",
      "Avg = 1205.5731048979617\n",
      "Std = 4379.527597086793\n"
     ]
    }
   ],
   "source": [
    "# nb_data_items total_data_size priority cache_likelihood task_class_0.0 task_class_1.0 task_class_2.0 task_class_3.0\n",
    "\n",
    "LR_predicted = new_LR_model.predict([2.0, 640000.0, 128.0, 0, 0, 1, 0, 0])\n",
    "DNN_predicted = new_DNN_model.predict([2.0, 640000.0, 128.0, 0, 0, 1, 0, 0])\n",
    "Actual = '566.124'\n",
    "print('Actual = ' + str(Actual) + ' LR_predicted ' + str(LR_predicted) + ' DNN_predicted ' + str(DNN_predicted))\n",
    "\n",
    "filter = (li[2]['task_class_id'] == 1 )\n",
    "df_2 = li[2][filter]\n",
    "print('----------------- Class 2 -------------------------- ')\n",
    "print('Min = ' + str(df_2['exec_time'].min()))\n",
    "print('Max = ' + str(df_2['exec_time'].max()))\n",
    "print('Avg = ' + str(sum(df_2['exec_time']) / len(df_2['exec_time'])))\n",
    "print('Std = ' + str(df_2['exec_time'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06b715b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual = 410.847 LR_predicted [[460.452]] DNN_predicted [[420.474]]\n",
      "-----------------Class-------------------------- \n",
      "Min = 174.193\n",
      "Max = 115778.071\n",
      "Avg = 1317.3406866666628\n",
      "Std = 5363.1834662625515\n"
     ]
    }
   ],
   "source": [
    "# nb_data_items total_data_size priority cache_likelihood task_class_0.0 task_class_1.0 task_class_2.0 task_class_3.0\n",
    "\n",
    "LR_predicted = new_LR_model.predict([2.0, 640000.0, 45.0, 0, 0, 0, 1, 0])\n",
    "DNN_predicted = new_DNN_model.predict([2.0, 640000.0, 45.0, 0, 0, 0, 1, 0])\n",
    "Actual = '410.847'\n",
    "print('Actual = ' + str(Actual) + ' LR_predicted ' + str(LR_predicted) + ' DNN_predicted ' + str(DNN_predicted))\n",
    "\n",
    "filter = (li[2]['task_class_id'] == 2 )\n",
    "df_2 = li[2][filter]\n",
    "print('----------------- Class 2 -------------------------- ')\n",
    "print('Min = ' + str(df_2['exec_time'].min()))\n",
    "print('Max = ' + str(df_2['exec_time'].max()))\n",
    "print('Avg = ' + str(sum(df_2['exec_time']) / len(df_2['exec_time'])))\n",
    "print('Std = ' + str(df_2['exec_time'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4680e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual = 582.046 LR_predicted [[672.263]] DNN_predicted [[1106.801]]\n",
      "----------------- Class 3 -------------------------- \n",
      "Min = 484.341\n",
      "Max = 158086.646\n",
      "Avg = 1769.7356544217769\n",
      "Std = 6268.618821464601\n"
     ]
    }
   ],
   "source": [
    "# nb_data_items total_data_size priority cache_likelihood task_class_0.0 task_class_1.0 task_class_2.0 task_class_3.0\n",
    "\n",
    "LR_predicted = new_LR_model.predict([3.0, 960000.0, 729588.0, 0, 0, 0, 0, 1])\n",
    "DNN_predicted = new_DNN_model.predict([3.0, 960000.0, 729588.0, 0, 0, 0, 0, 1])\n",
    "Actual = '582.046'\n",
    "print('Actual = ' + str(Actual) + ' LR_predicted ' + str(LR_predicted) + ' DNN_predicted ' + str(DNN_predicted))\n",
    "\n",
    "filter = (li[2]['task_class_id'] == 3 )\n",
    "df_2 = li[2][filter]\n",
    "print('----------------- Class 3 -------------------------- ')\n",
    "print('Min = ' + str(df_2['exec_time'].min()))\n",
    "print('Max = ' + str(df_2['exec_time'].max()))\n",
    "print('Avg = ' + str(sum(df_2['exec_time']) / len(df_2['exec_time'])))\n",
    "print('Std = ' + str(df_2['exec_time'].std()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85899f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
